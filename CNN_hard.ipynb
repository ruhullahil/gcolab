{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_hard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruhullahil/gcolab/blob/master/CNN_hard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NfhUuH-8eBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aDlpVv_949T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Convolution:\n",
        "    '''\n",
        "    Applies Convolution to the input image\n",
        "    - image is a numpy 2d array\n",
        "    \n",
        "    filter_size is a tuple which takes the row and column size of 2d ConvLayer\n",
        "    num_filters is the number of filters/kernel to use\n",
        "    \n",
        "    This convolutional layer uses valid padding\n",
        "    '''\n",
        "    def __init__(self, filter_size, num_filters, scale_value=9):\n",
        "        self.num_filters = num_filters\n",
        "        self.n, self.m = filter_size\n",
        "        print(self.n,self.m)\n",
        "        \n",
        "        # filters is a 3d array with dimensions (num_filters, n, m)\n",
        "        # We divide by 9 to reduce the variance of our initial values\n",
        "        self.filters = np.random.randn(num_filters, self.n, self.m) \n",
        "        print(\"Kernel shape \", self.filters.shape)\n",
        "        \n",
        "    def iterate_regions(self, image):\n",
        "        '''\n",
        "        Generates all possible nxm image regions using valid padding.\n",
        "        - image is a 2d numpy array\n",
        "        '''\n",
        "        h, w = image.shape\n",
        "        for i in range(h-(self.n-1)):\n",
        "            for j in range(w-(self.m-1)):\n",
        "                img_region = image[i:i+self.n, j:j+self.m]\n",
        "                yield img_region, i, j\n",
        "    \n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Performs a forward pass of the conv layer using the given input.\n",
        "        Returns a 3d numpy array with dimensions (h, w, num_filters).\n",
        "        - input is a 2d numpy array\n",
        "        '''\n",
        "        h, w = input.shape\n",
        "        output = np.zeros((h-(self.n-1), w-(self.m-1), self.num_filters))\n",
        "        \n",
        "        for img_region, i, j in self.iterate_regions(input):\n",
        "            output[i, j] = np.sum(img_region * self.filters, axis=(1, 2))\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9-luOYm-DJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaxPool:\n",
        "    '''\n",
        "    Generates non-overlapping nxm image regions to pool over.\n",
        "    - image is a 2d numpy array\n",
        "    \n",
        "    poolShape is the row and column size of the pool\n",
        "    '''\n",
        "    def __init__(self, poolShape):\n",
        "        self.n, self.m = poolShape\n",
        "    \n",
        "    def iterate_regions(self, image):\n",
        "        h, w = image.shape[:2]\n",
        "        \n",
        "        new_h = h // self.n\n",
        "        new_w = w // self.m\n",
        "        \n",
        "        for i in range(new_h):\n",
        "            for j in range(new_w):\n",
        "                p_start = i*self.n\n",
        "                p_end = p_start+self.n\n",
        "                q_start = i*self.m\n",
        "                q_end = q_start+self.m\n",
        "                im_region = image[p_start:p_end, q_start:q_end]\n",
        "                yield im_region, i, j\n",
        "    \n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Performs a forward pass of the maxpool layer using the given input.\n",
        "        Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).\n",
        "        - input is a 3d numpy array with dimensions (h, w, num_filters)\n",
        "        '''\n",
        "        h, w, num_filters = input.shape\n",
        "        output = np.zeros((h // self.n, w // self.m, num_filters))\n",
        "        \n",
        "        for im_region, i, j in self.iterate_regions(input):\n",
        "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDYCigEz-MPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Softmax:\n",
        "    '''\n",
        "    Input parameters:\n",
        "    input_len = total nodes\n",
        "    nodes = total number of classes, refers to the nodes of softmax\n",
        "        \n",
        "    Flatterns the whole input dimention and applies softmax to the flattened vector\n",
        "    '''\n",
        "    def __init__(self, input_len, softmax_nodes):\n",
        "        # We divide by input_len to reduce the variance of our initial values\n",
        "        self.weights = np.random.randn(input_len, softmax_nodes) / input_len\n",
        "        self.biases = np.zeros(softmax_nodes)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        '''\n",
        "        Performs a forward pass of the softmax layer using the given input.\n",
        "        Returns a 1d numpy array containing the respective probability values.\n",
        "        - input can be any array with any dimensions.\n",
        "        '''\n",
        "        input = input.flatten()\n",
        "        input_len, softmax_nodes = self.weights.shape\n",
        "        \n",
        "        totals = np.dot(input, self.weights) + self.biases\n",
        "        exp = np.exp(totals)\n",
        "        return exp / np.sum(exp, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82owL-Ty-SZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feedToCNN(image, label, conv, pool, softmax):\n",
        "    '''\n",
        "    Completes a forward pass of the CNN and calculates the accuracy and\n",
        "    cross-entropy loss.\n",
        "    - image is a 2d numpy array\n",
        "    - label is a digit\n",
        "    - conv is Convolution object\n",
        "    - pool is Maxpool object\n",
        "    - softmax is Softmax object\n",
        "    '''\n",
        "    \n",
        "    # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n",
        "    # to work with. This is standard practice.\n",
        "    out = conv.forward((image / 255) - 0.5)\n",
        "    print(np.array(out).shape)\n",
        "    out = pool.forward(out)\n",
        "    out = softmax.forward(out)\n",
        "    \n",
        "    # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
        "    loss = -np.log(out[label])\n",
        "    acc = 1 if np.argmax(out) == label else 0\n",
        "    \n",
        "    return out, loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKZxjTLz-c-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotFigs(images, title=None):\n",
        "    w=10\n",
        "    h=10\n",
        "    \n",
        "    fig=plt.figure(figsize=(8, 8))\n",
        "    if title:\n",
        "        fig.suptitle(title)\n",
        " \n",
        "    rows = images.shape[-1]//2\n",
        "    columns = rows + (images.shape[-1]%2)\n",
        "    \n",
        "    for i in range(images.shape[-1]):\n",
        "        fig.add_subplot(rows, columns, i+1)\n",
        "        plt.imshow(images[:, :, i], cmap='gray')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7x4kGdk-mu4",
        "colab_type": "code",
        "outputId": "eaf04445-12e3-47e6-ec04-d451fbfaafc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Data of mnist digit\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Defining Layers of CNN\n",
        "conv = Convolution((3, 3), 8)\n",
        "pool = MaxPool((2, 2))\n",
        "softmax = Softmax(13 * 13 * 8, 10)\n",
        "\n",
        "loss = 0\n",
        "num_correct = 0\n",
        "for i, (im, label) in enumerate(zip(x_train[:1000], y_train[:1000])):\n",
        "  _, l, acc = feedToCNN(im, label, conv, pool, softmax)\n",
        "  loss += l\n",
        "  num_correct += acc\n",
        "\n",
        "  # Print stats every 100 steps.\n",
        "  if i % 100 == 99:\n",
        "    print(\n",
        "      '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%'\n",
        "      %(i + 1, loss / 100, num_correct)\n",
        "    )\n",
        "    loss, num_correct = (0, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 3\n",
            "Kernel shape  (8, 3, 3)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 100] Past 100 steps: Average Loss 2.305 | Accuracy: 7%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 200] Past 100 steps: Average Loss 2.301 | Accuracy: 9%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 300] Past 100 steps: Average Loss 2.301 | Accuracy: 11%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 400] Past 100 steps: Average Loss 2.299 | Accuracy: 12%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 500] Past 100 steps: Average Loss 2.302 | Accuracy: 10%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 600] Past 100 steps: Average Loss 2.301 | Accuracy: 11%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 700] Past 100 steps: Average Loss 2.298 | Accuracy: 13%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 800] Past 100 steps: Average Loss 2.309 | Accuracy: 6%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 900] Past 100 steps: Average Loss 2.302 | Accuracy: 10%\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "(26, 26, 8)\n",
            "[Step 1000] Past 100 steps: Average Loss 2.306 | Accuracy: 3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhH_dScDDwbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}